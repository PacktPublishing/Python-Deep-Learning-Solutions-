{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_val, y_val) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255.\n",
    "X_val = X_val.astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "y_val = np_utils.to_categorical(y_val, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,403,050\n",
      "Trainable params: 1,403,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train[0].shape\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=5, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "n_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "50000/50000 [==============================] - 19s - loss: 1.8377 - acc: 0.3088 - val_loss: 1.4586 - val_acc: 0.4580\n",
      "Epoch 2/300\n",
      "50000/50000 [==============================] - 17s - loss: 1.3700 - acc: 0.4958 - val_loss: 1.1976 - val_acc: 0.5694\n",
      "Epoch 3/300\n",
      "50000/50000 [==============================] - 17s - loss: 1.1704 - acc: 0.5783 - val_loss: 1.0514 - val_acc: 0.6183\n",
      "Epoch 4/300\n",
      "50000/50000 [==============================] - 17s - loss: 1.0285 - acc: 0.6286 - val_loss: 0.9112 - val_acc: 0.6787\n",
      "Epoch 5/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.9276 - acc: 0.6720 - val_loss: 0.8432 - val_acc: 0.7026\n",
      "Epoch 6/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.8487 - acc: 0.7019 - val_loss: 0.7654 - val_acc: 0.7292\n",
      "Epoch 7/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.7901 - acc: 0.7198 - val_loss: 0.7446 - val_acc: 0.7409\n",
      "Epoch 8/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.7376 - acc: 0.7384 - val_loss: 0.7600 - val_acc: 0.7409\n",
      "Epoch 9/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.6996 - acc: 0.7549 - val_loss: 0.6903 - val_acc: 0.7583\n",
      "Epoch 10/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.6589 - acc: 0.7705 - val_loss: 0.6388 - val_acc: 0.7784\n",
      "Epoch 11/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.6275 - acc: 0.7781 - val_loss: 0.6260 - val_acc: 0.7857\n",
      "Epoch 12/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.5818 - acc: 0.7933 - val_loss: 0.6080 - val_acc: 0.7894\n",
      "Epoch 13/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.5730 - acc: 0.7985 - val_loss: 0.5822 - val_acc: 0.7974\n",
      "Epoch 14/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.5507 - acc: 0.8072 - val_loss: 0.5842 - val_acc: 0.7968\n",
      "Epoch 15/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.5209 - acc: 0.8163 - val_loss: 0.5979 - val_acc: 0.7960\n",
      "Epoch 16/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.5072 - acc: 0.8210 - val_loss: 0.5734 - val_acc: 0.8054\n",
      "Epoch 17/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.4877 - acc: 0.8274 - val_loss: 0.5703 - val_acc: 0.8083\n",
      "Epoch 18/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.4744 - acc: 0.8315 - val_loss: 0.5776 - val_acc: 0.8042\n",
      "Epoch 19/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.4641 - acc: 0.8364 - val_loss: 0.5631 - val_acc: 0.8105\n",
      "Epoch 20/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.4425 - acc: 0.8437 - val_loss: 0.5818 - val_acc: 0.8088\n",
      "Epoch 21/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.4284 - acc: 0.8479 - val_loss: 0.5564 - val_acc: 0.8180\n",
      "Epoch 22/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.4185 - acc: 0.8526 - val_loss: 0.5519 - val_acc: 0.8172\n",
      "Epoch 23/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.4104 - acc: 0.8559 - val_loss: 0.5622 - val_acc: 0.8216\n",
      "Epoch 24/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3939 - acc: 0.8609 - val_loss: 0.5612 - val_acc: 0.8153\n",
      "Epoch 25/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3918 - acc: 0.8612 - val_loss: 0.5609 - val_acc: 0.8187\n",
      "Epoch 26/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3853 - acc: 0.8623 - val_loss: 0.5332 - val_acc: 0.8268\n",
      "Epoch 27/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3752 - acc: 0.8664 - val_loss: 0.5523 - val_acc: 0.8174\n",
      "Epoch 28/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3624 - acc: 0.8706 - val_loss: 0.5493 - val_acc: 0.8232\n",
      "Epoch 29/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3526 - acc: 0.8733 - val_loss: 0.5434 - val_acc: 0.8283\n",
      "Epoch 30/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3467 - acc: 0.8782 - val_loss: 0.5633 - val_acc: 0.8194\n",
      "Epoch 31/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3436 - acc: 0.8782 - val_loss: 0.5579 - val_acc: 0.8235\n",
      "Epoch 32/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3333 - acc: 0.8814 - val_loss: 0.5673 - val_acc: 0.8216\n",
      "Epoch 33/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3327 - acc: 0.8807 - val_loss: 0.5532 - val_acc: 0.8240\n",
      "Epoch 34/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3164 - acc: 0.8866 - val_loss: 0.5444 - val_acc: 0.8319\n",
      "Epoch 35/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3225 - acc: 0.8848 - val_loss: 0.5422 - val_acc: 0.8290\n",
      "Epoch 36/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3071 - acc: 0.8899 - val_loss: 0.5464 - val_acc: 0.8308\n",
      "Epoch 37/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3002 - acc: 0.8922 - val_loss: 0.5886 - val_acc: 0.8203\n",
      "Epoch 38/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.3052 - acc: 0.8916 - val_loss: 0.5737 - val_acc: 0.8214\n",
      "Epoch 39/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.2915 - acc: 0.8951 - val_loss: 0.5656 - val_acc: 0.8249\n",
      "Epoch 40/300\n",
      "50000/50000 [==============================] - 17s - loss: 0.2893 - acc: 0.8962 - val_loss: 0.5990 - val_acc: 0.8193\n",
      "Epoch 00039: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, verbose=1, validation_data=(X_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,406,890\n",
      "Trainable params: 1,404,970\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bn = Sequential()\n",
    "\n",
    "model_bn.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape, padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model_bn.add(Dropout(0.25))\n",
    "\n",
    "model_bn.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model_bn.add(Dropout(0.25))\n",
    "\n",
    "model_bn.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model_bn.add(Dropout(0.25))\n",
    "\n",
    "model_bn.add(Flatten())\n",
    "model_bn.add(Dense(512, activation='relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Dropout(0.5))\n",
    "model_bn.add(Dense(128, activation='relu'))\n",
    "model_bn.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_bn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_bn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "50000/50000 [==============================] - 25s - loss: 1.6563 - acc: 0.4170 - val_loss: 4.1822 - val_acc: 0.1000\n",
      "Epoch 2/300\n",
      "50000/50000 [==============================] - 25s - loss: 1.1806 - acc: 0.5751 - val_loss: 3.1617 - val_acc: 0.2105\n",
      "Epoch 3/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.9612 - acc: 0.6564 - val_loss: 0.9644 - val_acc: 0.6526\n",
      "Epoch 4/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.8349 - acc: 0.7038 - val_loss: 0.8607 - val_acc: 0.6936\n",
      "Epoch 5/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.7495 - acc: 0.7339 - val_loss: 0.7269 - val_acc: 0.7481\n",
      "Epoch 6/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.6805 - acc: 0.7591 - val_loss: 0.6825 - val_acc: 0.7654\n",
      "Epoch 7/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.6237 - acc: 0.7786 - val_loss: 0.7846 - val_acc: 0.7303\n",
      "Epoch 8/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.5832 - acc: 0.7942 - val_loss: 0.6100 - val_acc: 0.7888\n",
      "Epoch 9/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.5336 - acc: 0.8120 - val_loss: 0.6478 - val_acc: 0.7816\n",
      "Epoch 10/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.5039 - acc: 0.8214 - val_loss: 0.5782 - val_acc: 0.8013\n",
      "Epoch 11/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.4786 - acc: 0.8297 - val_loss: 0.5699 - val_acc: 0.8101\n",
      "Epoch 12/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.4406 - acc: 0.8446 - val_loss: 0.5661 - val_acc: 0.8141\n",
      "Epoch 13/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.4205 - acc: 0.8525 - val_loss: 0.5730 - val_acc: 0.8092\n",
      "Epoch 14/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.3972 - acc: 0.8605 - val_loss: 0.5847 - val_acc: 0.8120\n",
      "Epoch 15/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.3769 - acc: 0.8656 - val_loss: 0.5527 - val_acc: 0.8217\n",
      "Epoch 16/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.3551 - acc: 0.8728 - val_loss: 0.5410 - val_acc: 0.8220\n",
      "Epoch 17/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.3326 - acc: 0.8821 - val_loss: 0.5010 - val_acc: 0.8385\n",
      "Epoch 18/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.3235 - acc: 0.8848 - val_loss: 0.5270 - val_acc: 0.8319\n",
      "Epoch 19/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.3019 - acc: 0.8912 - val_loss: 0.5022 - val_acc: 0.8374\n",
      "Epoch 20/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.2895 - acc: 0.8970 - val_loss: 0.5196 - val_acc: 0.8416\n",
      "Epoch 21/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.2722 - acc: 0.9028 - val_loss: 0.5222 - val_acc: 0.8373\n",
      "Epoch 22/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.2619 - acc: 0.9040 - val_loss: 0.5890 - val_acc: 0.8223\n",
      "Epoch 23/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.2563 - acc: 0.9072 - val_loss: 0.5089 - val_acc: 0.8392\n",
      "Epoch 24/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.2462 - acc: 0.9111 - val_loss: 0.5550 - val_acc: 0.8329\n",
      "Epoch 25/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.2324 - acc: 0.9171 - val_loss: 0.5500 - val_acc: 0.8410\n",
      "Epoch 26/300\n",
      "50000/50000 [==============================] - 25s - loss: 0.2270 - acc: 0.9187 - val_loss: 0.5605 - val_acc: 0.8388\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    " history_bn = model_bn.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcY0saRgjDGmyf8D4mfNoatUjdoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f03b03ceac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc_bn = history_bn.history['val_acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(range(len(val_acc)), val_acc, label='CNN model')\n",
    "plt.plot(range(len(val_acc_bn)), val_acc_bn, label='CNN model with BN')\n",
    "plt.title('Validation accuracy on Cifar10 dataset')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8416 0.8319\n",
      "26 40\n"
     ]
    }
   ],
   "source": [
    "print(max(val_acc_bn), max(val_acc))\n",
    "print(len(val_acc_bn), len(val_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
