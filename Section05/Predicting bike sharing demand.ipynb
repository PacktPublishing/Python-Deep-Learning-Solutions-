{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi, sin, cos\n",
    "from datetime import datetime\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/bike-sharing/train.csv')\n",
    "test = pd.read_csv('Data/bike-sharing/test.csv')\n",
    "data = pd.concat([train, test])\n",
    "test_split = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atemp</th>\n",
       "      <th>casual</th>\n",
       "      <th>count</th>\n",
       "      <th>datetime</th>\n",
       "      <th>holiday</th>\n",
       "      <th>humidity</th>\n",
       "      <th>registered</th>\n",
       "      <th>season</th>\n",
       "      <th>temp</th>\n",
       "      <th>weather</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>workingday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.395</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.635</td>\n",
       "      <td>8.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.635</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.395</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    atemp  casual  count             datetime  holiday  humidity  registered  \\\n",
       "0  14.395     3.0   16.0  2011-01-01 00:00:00        0        81        13.0   \n",
       "1  13.635     8.0   40.0  2011-01-01 01:00:00        0        80        32.0   \n",
       "2  13.635     5.0   32.0  2011-01-01 02:00:00        0        80        27.0   \n",
       "3  14.395     3.0   13.0  2011-01-01 03:00:00        0        75        10.0   \n",
       "4  14.395     0.0    1.0  2011-01-01 04:00:00        0        75         1.0   \n",
       "\n",
       "   season  temp  weather  windspeed  workingday  \n",
       "0       1  9.84        1        0.0           0  \n",
       "1       1  9.02        1        0.0           0  \n",
       "2       1  9.02        1        0.0           0  \n",
       "3       1  9.84        1        0.0           0  \n",
       "4       1  9.84        1        0.0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hour'] = data.apply(lambda x: datetime.strptime(x['datetime'], '%Y-%m-%d %H:%M:%S').hour, axis=1)\n",
    "data['weekday'] = data.apply(lambda x: datetime.strptime(x['datetime'], '%Y-%m-%d %H:%M:%S').weekday(), axis=1)\n",
    "data['month'] = data.apply(lambda x: datetime.strptime(x['datetime'], '%Y-%m-%d %H:%M:%S').month, axis=1)\n",
    "data['year'] = data.apply(lambda x: datetime.strptime(x['datetime'], '%Y-%m-%d %H:%M:%S').year, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hour_sin'] = data.apply(lambda x: sin(x['hour'] / 24.0 * 2 * pi), axis=1)\n",
    "data['hour_cos'] = data.apply(lambda x: cos(x['hour'] / 24.0 * 2 * pi), axis=1)\n",
    "data['weekday_sin'] = data.apply(lambda x: sin(x['weekday'] / 7.0 * 2 * pi), axis=1)\n",
    "data['weekday_cos'] = data.apply(lambda x: cos(x['weekday'] / 7.0 * 2 * pi), axis=1)\n",
    "data['month_sin'] = data.apply(lambda x: sin(((x['month'] - 5) % 12) / 12.0 * 2 * pi), axis=1)\n",
    "data['month_cos'] = data.apply(lambda x: cos(((x['month'] - 5) % 12) / 12.0 * 2 * pi), axis=1)\n",
    "data['season_sin'] = data.apply(lambda x: sin(((x['season'] - 3) % 4) / 4.0 * 2 * pi), axis=1)\n",
    "data['season_cos'] = data.apply(lambda x: cos(((x['season'] - 3) % 4) / 4.0 * 2 * pi), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:test_split].drop(['datetime', 'casual', 'registered', 'count'], inplace=False, axis=1)\n",
    "X_test = data[test_split:].drop(['datetime', 'casual', 'registered', 'count'], inplace=False, axis=1)\n",
    "y_train = data['count'][:test_split]\n",
    "y_test = data['count'][test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=X_train.shape[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "opt = Adam()\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9797 samples, validate on 1089 samples\n",
      "Epoch 1/100\n",
      "9797/9797 [==============================] - 1s 87us/step - loss: 4.0808 - val_loss: 2.1124\n",
      "Epoch 2/100\n",
      "9797/9797 [==============================] - 0s 41us/step - loss: 0.9957 - val_loss: 1.1161\n",
      "Epoch 3/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.6625 - val_loss: 0.7477\n",
      "Epoch 4/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.5375 - val_loss: 0.5871\n",
      "Epoch 5/100\n",
      "9797/9797 [==============================] - 0s 44us/step - loss: 0.4466 - val_loss: 0.4750\n",
      "Epoch 6/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.3837 - val_loss: 0.3950\n",
      "Epoch 7/100\n",
      "9797/9797 [==============================] - 0s 42us/step - loss: 0.3475 - val_loss: 0.3595\n",
      "Epoch 8/100\n",
      "9797/9797 [==============================] - 0s 42us/step - loss: 0.3295 - val_loss: 0.3204\n",
      "Epoch 9/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.3138 - val_loss: 0.3109\n",
      "Epoch 10/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.3045 - val_loss: 0.2963\n",
      "Epoch 11/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.2981 - val_loss: 0.2909\n",
      "Epoch 12/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.2936 - val_loss: 0.2816\n",
      "Epoch 13/100\n",
      "9797/9797 [==============================] - 0s 50us/step - loss: 0.2872 - val_loss: 0.2788\n",
      "Epoch 14/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.2785 - val_loss: 0.2715\n",
      "Epoch 15/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.2736 - val_loss: 0.2709\n",
      "Epoch 16/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.2682 - val_loss: 0.2715\n",
      "Epoch 17/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.2650 - val_loss: 0.2623\n",
      "Epoch 18/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.2586 - val_loss: 0.2566\n",
      "Epoch 19/100\n",
      "9797/9797 [==============================] - 0s 41us/step - loss: 0.2506 - val_loss: 0.2553\n",
      "Epoch 20/100\n",
      "9797/9797 [==============================] - 0s 42us/step - loss: 0.2448 - val_loss: 0.2555\n",
      "Epoch 21/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.2378 - val_loss: 0.2436\n",
      "Epoch 22/100\n",
      "9797/9797 [==============================] - 0s 44us/step - loss: 0.2281 - val_loss: 0.2349\n",
      "Epoch 23/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.2232 - val_loss: 0.2325\n",
      "Epoch 24/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.2142 - val_loss: 0.2341\n",
      "Epoch 25/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.2060 - val_loss: 0.2082\n",
      "Epoch 26/100\n",
      "9797/9797 [==============================] - 0s 44us/step - loss: 0.1982 - val_loss: 0.2091\n",
      "Epoch 27/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.1926 - val_loss: 0.2087\n",
      "Epoch 28/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.1831 - val_loss: 0.1921\n",
      "Epoch 29/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.1774 - val_loss: 0.1865\n",
      "Epoch 30/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.1698 - val_loss: 0.1951\n",
      "Epoch 31/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.1648 - val_loss: 0.1800\n",
      "Epoch 32/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.1577 - val_loss: 0.1790\n",
      "Epoch 33/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.1532 - val_loss: 0.1712\n",
      "Epoch 34/100\n",
      "9797/9797 [==============================] - 0s 42us/step - loss: 0.1482 - val_loss: 0.1647\n",
      "Epoch 35/100\n",
      "9797/9797 [==============================] - 0s 48us/step - loss: 0.1458 - val_loss: 0.1701\n",
      "Epoch 36/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.1412 - val_loss: 0.1683\n",
      "Epoch 37/100\n",
      "9797/9797 [==============================] - 0s 41us/step - loss: 0.1364 - val_loss: 0.1626\n",
      "Epoch 38/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.1357 - val_loss: 0.1556\n",
      "Epoch 39/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.1283 - val_loss: 0.1470\n",
      "Epoch 40/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.1269 - val_loss: 0.1504\n",
      "Epoch 41/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.1233 - val_loss: 0.1561\n",
      "Epoch 42/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.1240 - val_loss: 0.1386\n",
      "Epoch 43/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.1198 - val_loss: 0.1430\n",
      "Epoch 44/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.1182 - val_loss: 0.1489\n",
      "Epoch 45/100\n",
      "9797/9797 [==============================] - 0s 49us/step - loss: 0.1164 - val_loss: 0.1447\n",
      "Epoch 46/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.1141 - val_loss: 0.1275\n",
      "Epoch 47/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.1124 - val_loss: 0.1348\n",
      "Epoch 48/100\n",
      "9797/9797 [==============================] - 1s 52us/step - loss: 0.1095 - val_loss: 0.1474\n",
      "Epoch 49/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.1116 - val_loss: 0.1383\n",
      "Epoch 50/100\n",
      "9797/9797 [==============================] - 0s 44us/step - loss: 0.1083 - val_loss: 0.1438\n",
      "Epoch 51/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.1049 - val_loss: 0.1337\n",
      "Epoch 52/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.1049 - val_loss: 0.1343\n",
      "Epoch 53/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.1042 - val_loss: 0.1393\n",
      "Epoch 54/100\n",
      "9797/9797 [==============================] - 0s 48us/step - loss: 0.1001 - val_loss: 0.1258\n",
      "Epoch 55/100\n",
      "9797/9797 [==============================] - 0s 42us/step - loss: 0.1016 - val_loss: 0.1394\n",
      "Epoch 56/100\n",
      "9797/9797 [==============================] - 0s 49us/step - loss: 0.0990 - val_loss: 0.1308\n",
      "Epoch 57/100\n",
      "9797/9797 [==============================] - 1s 52us/step - loss: 0.0987 - val_loss: 0.1386\n",
      "Epoch 58/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.0996 - val_loss: 0.1349\n",
      "Epoch 59/100\n",
      "9797/9797 [==============================] - 0s 50us/step - loss: 0.0977 - val_loss: 0.1438\n",
      "Epoch 60/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.0956 - val_loss: 0.1497\n",
      "Epoch 61/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.0940 - val_loss: 0.1451\n",
      "Epoch 62/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.0928 - val_loss: 0.1421\n",
      "Epoch 63/100\n",
      "9797/9797 [==============================] - 0s 44us/step - loss: 0.0921 - val_loss: 0.1339\n",
      "Epoch 64/100\n",
      "9797/9797 [==============================] - 0s 42us/step - loss: 0.0913 - val_loss: 0.1319\n",
      "Epoch 65/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.0893 - val_loss: 0.1343\n",
      "Epoch 66/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0904 - val_loss: 0.1373\n",
      "Epoch 67/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.0913 - val_loss: 0.1475\n",
      "Epoch 68/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.0887 - val_loss: 0.1306\n",
      "Epoch 69/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.0875 - val_loss: 0.1452\n",
      "Epoch 70/100\n",
      "9797/9797 [==============================] - 0s 48us/step - loss: 0.0859 - val_loss: 0.1273\n",
      "Epoch 71/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.0862 - val_loss: 0.1350\n",
      "Epoch 72/100\n",
      "9797/9797 [==============================] - 0s 44us/step - loss: 0.0857 - val_loss: 0.1237\n",
      "Epoch 73/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.0850 - val_loss: 0.1516\n",
      "Epoch 74/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.0844 - val_loss: 0.1555\n",
      "Epoch 75/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0837 - val_loss: 0.1552\n",
      "Epoch 76/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.0839 - val_loss: 0.1512\n",
      "Epoch 77/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.0835 - val_loss: 0.1450\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.0835 - val_loss: 0.1336\n",
      "Epoch 79/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.0825 - val_loss: 0.1311\n",
      "Epoch 80/100\n",
      "9797/9797 [==============================] - 0s 43us/step - loss: 0.0803 - val_loss: 0.1484\n",
      "Epoch 81/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0818 - val_loss: 0.1291\n",
      "Epoch 82/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.0844 - val_loss: 0.1225\n",
      "Epoch 83/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0790 - val_loss: 0.1378\n",
      "Epoch 84/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0788 - val_loss: 0.1398\n",
      "Epoch 85/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.0768 - val_loss: 0.1402\n",
      "Epoch 86/100\n",
      "9797/9797 [==============================] - 0s 42us/step - loss: 0.0784 - val_loss: 0.1311\n",
      "Epoch 87/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0779 - val_loss: 0.1297\n",
      "Epoch 88/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0782 - val_loss: 0.1400\n",
      "Epoch 89/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0760 - val_loss: 0.1496\n",
      "Epoch 90/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0755 - val_loss: 0.1423\n",
      "Epoch 91/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0755 - val_loss: 0.1627\n",
      "Epoch 92/100\n",
      "9797/9797 [==============================] - 0s 47us/step - loss: 0.0818 - val_loss: 0.1414\n",
      "Epoch 93/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0801 - val_loss: 0.1440\n",
      "Epoch 94/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0737 - val_loss: 0.1299\n",
      "Epoch 95/100\n",
      "9797/9797 [==============================] - 0s 44us/step - loss: 0.0753 - val_loss: 0.1379\n",
      "Epoch 96/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.0739 - val_loss: 0.1264\n",
      "Epoch 97/100\n",
      "9797/9797 [==============================] - 0s 44us/step - loss: 0.0736 - val_loss: 0.1532\n",
      "Epoch 98/100\n",
      "9797/9797 [==============================] - 0s 45us/step - loss: 0.0716 - val_loss: 0.1476\n",
      "Epoch 99/100\n",
      "9797/9797 [==============================] - 0s 42us/step - loss: 0.0755 - val_loss: 0.1599\n",
      "Epoch 100/100\n",
      "9797/9797 [==============================] - 0s 46us/step - loss: 0.0736 - val_loss: 0.1483\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
    "history = model.fit(X_train, y_train, shuffle=True, epochs=n_epochs, batch_size=batch_size, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
