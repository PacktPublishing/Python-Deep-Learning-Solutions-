{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset can be downloaded at https://archive.ics.uci.edu/ml/machine-learning-databases/00275/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/bike-sharing/hour.csv')\n",
    "# Feature engineering\n",
    "ohe_features = ['season', 'weathersit', 'mnth', 'hr', 'weekday']\n",
    "for feature in ohe_features:\n",
    "    dummies = pd.get_dummies(data[feature], prefix=feature, drop_first=False)\n",
    "    data = pd.concat([data, dummies], axis=1)\n",
    "\n",
    "drop_features = ['instant', 'dteday', 'season', 'weathersit', 'weekday', 'atemp', 'mnth', 'workingday', 'hr', 'casual', 'registered']\n",
    "data = data.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_features = ['cnt', 'temp', 'hum', 'windspeed']\n",
    "scaled_features = {}\n",
    "for feature in norm_features:\n",
    "    mean, std = data[feature].mean(), data[feature].std()\n",
    "    scaled_features[feature] = [mean, std]\n",
    "    data.loc[:, feature] = (data[feature] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final month for testing\n",
    "test_data = data[-31*24:]\n",
    "data = data[:-31*24]\n",
    "\n",
    "# Extract the target field\n",
    "target_fields = ['cnt']\n",
    "features, targets = data.drop(target_fields, axis=1), data[target_fields]\n",
    "test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]\n",
    "\n",
    "# Create a validation set (based on the last )\n",
    "X_train, y_train = features[:-30*24], targets[:-30*24]\n",
    "X_val, y_val = features[-30*24:], targets[-30*24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(250, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer='sgd', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 1024\n",
    "\n",
    "history = model.fit(X_train.values, y_train['cnt'], \n",
    "    validation_data=(X_val.values, y_val['cnt']), \n",
    "    batch_size=batch_size, epochs=n_epochs, verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(history.history['loss'])), history.history['loss'], label='training')\n",
    "plt.plot(np.arange(len(history.history['val_loss'])), history.history['val_loss'], label='validation')\n",
    "plt.title('Overfit on Bike Sharing dataset')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum loss: ', min(history.history['val_loss']), \n",
    " '\\nAfter ', np.argmin(history.history['val_loss']), ' epochs')\n",
    "\n",
    "# Minimum loss:  0.129907280207 \n",
    "# After  980  epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop = Sequential()\n",
    "model_drop.add(Dense(250, input_dim=X_train.shape[1], activation='relu'))\n",
    "model_drop.add(Dropout(0.20))\n",
    "model_drop.add(Dense(150, activation='relu'))\n",
    "model_drop.add(Dropout(0.20))\n",
    "model_drop.add(Dense(50, activation='relu'))\n",
    "model_drop.add(Dropout(0.20))\n",
    "model_drop.add(Dense(25, activation='relu'))\n",
    "model_drop.add(Dropout(0.20))\n",
    "model_drop.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile model\n",
    "model_drop.compile(loss='mse', optimizer='sgd', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_drop = model_drop.fit(X_train.values, y_train['cnt'], \n",
    "    validation_data=(X_val.values, y_val['cnt']), \n",
    "    batch_size=batch_size, epochs=n_epochs, verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(history_drop.history['loss'])), history_drop.history['loss'], label='training')\n",
    "plt.plot(np.arange(len(history_drop.history['val_loss'])), history_drop.history['val_loss'], label='validation')\n",
    "plt.title('Use dropout for Bike Sharing dataset')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum loss: ', min(history_drop.history['val_loss']), \n",
    " '\\nAfter ', np.argmin(history_drop.history['val_loss']), ' epochs')\n",
    "\n",
    "# Minimum loss:  0.126063346863 \n",
    "# After  998  epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
